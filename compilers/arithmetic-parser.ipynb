{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a8c66b",
   "metadata": {},
   "source": [
    "# Συντακτικός αναλυτής LL(1)\n",
    "Με υλοποίηση \"recursive descent\", για τη γραμματική:\n",
    "\n",
    "~~~\n",
    "Grammar is:\n",
    "Stmt_list → Stmt Stmt_list | ε\n",
    "Stmt → id = Expr | print Expr\n",
    "Expr → Term Term_tail\n",
    "Term_tail → Addop Term Term_tail | ε\n",
    "Term → Factor Factor_tail\n",
    "Factor_tail → Multop Factor Factor_tail | ε\n",
    "Factor → (Expr) | id | number\n",
    "Addop → + | -\n",
    "Multop → * | /\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78332b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c82778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing error, a user-defined exception\n",
    "class ParseError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bf90c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class of recursive descent parser\n",
    "class MyParser():\n",
    "\n",
    "    def __init__(self,scanner):\n",
    "            \n",
    "        self.scanner = scanner\n",
    "        \n",
    "        # get initial input token\n",
    "        self.next_token,self.next_lexeme = self.scanner.read()\n",
    "\n",
    "\n",
    "    def match(self,expected):\n",
    "    \n",
    "        if self.next_token==expected:\n",
    "            # proceed to next token\n",
    "            self.next_token,self.next_lexeme = self.scanner.read()\n",
    "\n",
    "        else:\n",
    "            raise ParseError('Expected {}, found {} instead'.format(expected,self.next_token))\n",
    "            \n",
    "            \n",
    "    def parse(self):\n",
    "\n",
    "        # call method for starting symbol of grammar\n",
    "        self.Stmt_list()\n",
    "        \n",
    "        # keep the following to match end-of-text\n",
    "        self.match(None)\n",
    "\n",
    "\n",
    "    def Stmt_list(self):\n",
    "                \n",
    "        if self.next_token in ('id','print'):\n",
    "            # Stmt_list → Stmt Stmt_list\n",
    "            self.Stmt()\n",
    "            self.Stmt_list()\n",
    "        \n",
    "        elif self.next_token==None:\n",
    "            # Stmt_list → e\n",
    "            return\n",
    "                \n",
    "        else:\n",
    "            raise ParseError(\"In Stmt_list(), expecting id, print or EOT, found {} instead\".format(self.next_token))\n",
    "\n",
    "\n",
    "    def Stmt(self):\n",
    "                \n",
    "        if self.next_token=='id':\n",
    "            # Stmt → id = Expr\n",
    "            self.match('id')\n",
    "            self.match('=')\n",
    "            self.Expr()\n",
    "\n",
    "        elif self.next_token=='print':\n",
    "            # Stmt → print Expr\n",
    "            self.match('print')\n",
    "            self.Expr()\n",
    "                \n",
    "        else:\n",
    "            raise ParseError(\"In Stmt(), expecting id or print, found {} instead\".format(self.next_token))\n",
    "        \n",
    "\n",
    "    def Expr(self):\n",
    "                \n",
    "        if self.next_token in ('(','id','number'):\n",
    "            # Expr → Term Term_tail\n",
    "            self.Term()\n",
    "            self.Term_tail()\n",
    "                \n",
    "        else:\n",
    "            raise ParseError(\"In Expr(), expecting (, id or number, found {} instead\".format(self.next_token))    \n",
    "            \n",
    "\n",
    "    def Term_tail(self):\n",
    "                \n",
    "        if self.next_token in ('+','-'):\n",
    "            # Term_tail → Addop Term Term_tail\n",
    "            self.Addop()\n",
    "            self.Term()\n",
    "            self.Term_tail()\n",
    "\n",
    "        elif self.next_token in ('id','print',')',None):\n",
    "            # Term_tail → e\n",
    "            return\n",
    "                \n",
    "        else:\n",
    "            raise ParseError(\"In Term_tail(), expecting +, -, id, print, ) or EOT , found {} instead\".format(self.next_token))    \n",
    "\n",
    "\n",
    "    def Term(self):\n",
    "                \n",
    "        if self.next_token in ('(','id','number'):\n",
    "            # Term → Factor Factor_tail\n",
    "            self.Factor()\n",
    "            self.Factor_tail()\n",
    "                \n",
    "        else:\n",
    "            raise ParseError(\"In Term(), expecting (, id or number, found {} instead\".format(self.next_token))            \n",
    "            \n",
    "\n",
    "    def Factor_tail(self):\n",
    "                \n",
    "        if self.next_token in ('*','/'):\n",
    "            # Factor_tail → Multop Factor Factor_tail\n",
    "            self.Multop()\n",
    "            self.Factor()\n",
    "            self.Factor_tail()\n",
    "\n",
    "        elif self.next_token in ('+','-','id','print',')',None):\n",
    "            # Factor_tail → e\n",
    "            return\n",
    "                \n",
    "        else:\n",
    "            raise ParseError(\"In Factor_tail(), expecting *, /, +, -, id, print, ) or EOT, found {} instead\".format(self.next_token))    \n",
    "\n",
    "\n",
    "    def Factor(self):\n",
    "                \n",
    "        if self.next_token=='(':\n",
    "            # Factor → ( Expr )\n",
    "            self.match('(')\n",
    "            self.Expr()\n",
    "            self.match(')')\n",
    "\n",
    "        elif self.next_token=='id':\n",
    "            # Factor → id\n",
    "            self.match('id')\n",
    "\n",
    "        elif self.next_token=='number':\n",
    "            # Factor → number\n",
    "            self.match('number')\n",
    "                \n",
    "        else:\n",
    "            raise ParseError(\"In Factor(), expecting (, id or number, found {} instead\".format(self.next_token))\n",
    "\n",
    "\n",
    "    def Addop(self):\n",
    "                \n",
    "        if self.next_token=='+':\n",
    "            # Addop → +\n",
    "            self.match('+')\n",
    "\n",
    "        elif self.next_token=='-':\n",
    "            # Addop → -\n",
    "            self.match('-')\n",
    "\n",
    "        else:\n",
    "            raise ParseError(\"In Addop(), expecting + or -, found {} instead\".format(self.next_token))\n",
    "\n",
    "\n",
    "    def Multop(self):\n",
    "                \n",
    "        if self.next_token=='*':\n",
    "            # Multop → *\n",
    "            self.match('*')\n",
    "\n",
    "        elif self.next_token=='/':\n",
    "            # Multop → /\n",
    "            self.match('/')\n",
    "\n",
    "        else:\n",
    "            raise ParseError(\"In Multop(), expecting * or /, found {} instead\".format(self.next_token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4abb3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern definitions\n",
    "letter = plex.Range(\"AZaz\")\n",
    "digit = plex.Range(\"09\")\n",
    "underscore =  plex.Str(\"_\")\n",
    "\n",
    "number = plex.Rep1(digit) + plex.Opt(plex.Str('.') + plex.Rep1(digit))\n",
    "\n",
    "name = (letter | underscore) + plex.Rep(letter | digit | underscore)\n",
    "\n",
    "operator = plex.Any('+-*/=()')\n",
    "\n",
    "k_print = plex.Str('print')\n",
    "\n",
    "spaces = plex.Rep1(plex.Any(' \\t\\n'))\n",
    "\n",
    "# create plex lexicon\n",
    "lexicon = plex.Lexicon([\n",
    "      (number,'number'),\n",
    "      (operator,plex.TEXT),\n",
    "      (k_print,'print'),\n",
    "      (name,'id'),\n",
    "      (spaces,plex.IGNORE)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe099ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "# input text\n",
    "text = \"\"\"\n",
    "a = 99.3*(6+7.0/2.22)\n",
    "print a\n",
    "b = (a-999)/(23.32+11/7)\n",
    "print b*(4.44-a)\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "# create plex scanner for input text\n",
    "scanner = plex.Scanner(lexicon,StringIO(text))\n",
    "\n",
    "# create recursive descent parser\n",
    "parser = MyParser(scanner)\n",
    "\n",
    "try:\n",
    "    parser.parse()\n",
    "    \n",
    "except ParseError as e:\n",
    "    _,lineno,charno = scanner.position()\n",
    "    print('Syntax error at line:{} char:{}, {}'.format(lineno,charno+1,e))\n",
    "            \n",
    "except plex.errors.PlexError:            \n",
    "    _,lineno,charno = scanner.position()\n",
    "    print(\"Scanner Error at line {} char {}\".format(lineno,charno+1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
